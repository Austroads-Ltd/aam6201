{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src='../../img/WSP_red.png' style='height: 95px; float: left' alt='WSP Logo'/>\n",
    "<img src='../../img/austroads.png' style='height: 115px; float: right' alt='Client Logo'/>\n",
    "</div>\n",
    "<center><h2>AAM6201 Development of Machine-Learning Decision-Support tools for Pavement Asset Management<br>Case Study 1: Project Identification</h2></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic command to autoreload changes in src\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook preprocesses a dataset through the following steps in order:\n",
    "\n",
    "- Apply transformations \n",
    "- Adding new columns\n",
    "- Filtering the dataframe\n",
    "- Dropping unused columns\n",
    "\n",
    "As detailed in the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from src.nzta_configs.final_config import DATA_DIR\n",
    "from src.util import load_data\n",
    "NZTA_DATADIR = Path(DATA_DIR) / 'raw' / 'NZTA' / 'Raw Data'\n",
    "\n",
    "rutting_skid = load_data(NZTA_DATADIR / 'Rutting_Mean_Skid_Resistance_2016-20.csv')\n",
    "structure = load_data(NZTA_DATADIR / 'Surface_Structure.csv')\n",
    "traffic = load_data(NZTA_DATADIR / 'Traffic.csv')\n",
    "carriageway = load_data(NZTA_DATADIR / 'RAMM_Carriageway.csv')\n",
    "pavement_layer = load_data(NZTA_DATADIR / 'Pavement_Layer.csv')\n",
    "deflection_cracking = load_data(NZTA_DATADIR / 'NLTP_Unlimited_dTAGTL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutting_skid.loc[:, 'Year'] = pd.to_datetime(rutting_skid['Year'].str.split('-', expand=True)[0], format='%Y')\n",
    "rutting_skid = rutting_skid.replace({'-': np.nan})\n",
    "structure.loc[:, 'End'] = structure['Start'] + structure['Length']\n",
    "deflection_cracking.loc[:, 'Name'] = deflection_cracking['Name'].str.split('_', expand=True)[0]\n",
    "deflection_cracking = deflection_cracking.rename(columns={\n",
    "    'Name': 'RoadID',\n",
    "    'From': 'Start',\n",
    "    'To': 'End'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = structure.shape[0]\n",
    "structure_index_cols = ['Road ID', 'Start', 'End', 'Surfacing Date']\n",
    "structure = structure.drop_duplicates(structure_index_cols)\n",
    "new_shape = structure.shape[0]\n",
    "\n",
    "old_shape = rutting_skid.shape[0]\n",
    "rutting_skid_index_cols = ['Road Name', 'Start', 'End', 'Year']\n",
    "rutting_skid = rutting_skid.drop_duplicates(rutting_skid_index_cols)\n",
    "new_shape = rutting_skid.shape[0]\n",
    "\n",
    "old_shape = traffic.shape[0]\n",
    "traffic_index_cols = ['Road', 'Start', 'End', 'Count Date']\n",
    "traffic = traffic.drop_duplicates(traffic_index_cols)\n",
    "new_shape = traffic.shape[0]\n",
    "\n",
    "old_shape = carriageway.shape[0]\n",
    "carriageway_index_cols = ['Road', 'Start', 'End']\n",
    "carriageway = carriageway.drop_duplicates(carriageway_index_cols)\n",
    "new_shape = carriageway.shape[0]\n",
    "\n",
    "old_shape = pavement_layer.shape[0]\n",
    "pavement_layer_index_cols = ['Road', 'Start', 'End']\n",
    "pavement_layer = pavement_layer.drop_duplicates(pavement_layer_index_cols, keep='last')\n",
    "new_shape = pavement_layer.shape[0]\n",
    "\n",
    "old_shape = deflection_cracking.shape[0]\n",
    "deflection_cracking_index_cols = ['RoadID', 'Start', 'End']\n",
    "deflection_cracking = deflection_cracking.drop_duplicates(deflection_cracking_index_cols, keep='last')\n",
    "new_shape = deflection_cracking.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop na index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = structure.shape[0]\n",
    "structure = structure.dropna(subset=structure_index_cols, how='any')\n",
    "new_shape = structure.shape[0]\n",
    "\n",
    "old_shape = rutting_skid.shape[0]\n",
    "rutting_skid = rutting_skid.dropna(subset=rutting_skid_index_cols, how='any')\n",
    "new_shape = rutting_skid.shape[0]\n",
    "\n",
    "old_shape = traffic.shape[0]\n",
    "traffic = traffic.dropna(subset=traffic_index_cols, how='any')\n",
    "new_shape = traffic.shape[0]\n",
    "\n",
    "old_shape = carriageway.shape[0]\n",
    "carriageway = carriageway.dropna(subset=carriageway_index_cols, how='any')\n",
    "new_shape = carriageway.shape[0]\n",
    "\n",
    "old_shape = pavement_layer.shape[0]\n",
    "pavement_layer = pavement_layer.dropna(subset=pavement_layer_index_cols, how='any')\n",
    "new_shape = pavement_layer.shape[0]\n",
    "\n",
    "old_shape = deflection_cracking.shape[0]\n",
    "deflection_cracking = deflection_cracking.dropna(subset=deflection_cracking_index_cols, how='any')\n",
    "new_shape = deflection_cracking.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure dtypes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutting_skid_float_cols = ['ESC', 'ESC RV', 'NAASRA', 'Rutting Mean', 'Wheel Path', 'Left Path Depth', 'Right Path Depth']\n",
    "rutting_skid.loc[:, rutting_skid_float_cols] = rutting_skid[rutting_skid_float_cols].astype(float)\n",
    "\n",
    "structure_float_cols = ['Age', 'Width', 'Surface Depth', 'Modified Life', '1st Chip Size', 'Cutter Quantity']\n",
    "structure_string_cols = ['Surface Material', 'Binder Type']\n",
    "structure.loc[:, structure_float_cols] = structure[structure_float_cols].astype(float)\n",
    "structure.loc[:, structure_string_cols] = structure[structure_string_cols].astype(str)\n",
    "\n",
    "traffic_float_cols = ['ADT', '% Heavy Vehicles', 'VKT', 'ESA per Day', '% Cars', '% LCV', '% MCV', '% HCV I', '% HCV II', '% Bus', 'ESA MCV', 'ESA HCV I', 'ESA HCV II', 'ESA Heavy Vehicles', 'ESA Bus']\n",
    "traffic_string_cols = ['Carriageway No']\n",
    "traffic.loc[:, traffic_float_cols] = traffic[traffic_float_cols].astype(float)\n",
    "traffic.loc[:, traffic_string_cols] = traffic[traffic_string_cols].astype(str)\n",
    "\n",
    "carriageway_float_cols = ['Width', 'Number of Lanes', 'Lane Width']\n",
    "carriageway_string_cols = ['Pavement Type', 'Pavement Use', 'Urban/Rural', 'Carriageway No', 'Estimate Loading', 'Travel Direction']\n",
    "carriageway.loc[:, carriageway_float_cols] = carriageway[carriageway_float_cols].astype(float)\n",
    "carriageway.loc[:, carriageway_string_cols] = carriageway[carriageway_string_cols].astype(str)\n",
    "\n",
    "pavement_layer_float_cols = ['Age', 'Life', 'Layer Strength']\n",
    "pavement_layer_string_cols = ['Layer Material', 'Reconstructed', 'Layer or Subgrade']\n",
    "pavement_layer.loc[:, pavement_layer_float_cols] = pavement_layer[pavement_layer_float_cols].astype(float)\n",
    "pavement_layer.loc[:, pavement_layer_string_cols] = pavement_layer[pavement_layer_string_cols].astype(str)\n",
    "\n",
    "deflection_cracking_float_cols = ['def_fwd', 'Curvature', 'Curvature75', 'crk_alligator']\n",
    "deflection_cracking.loc[:, deflection_cracking_float_cols] = deflection_cracking[deflection_cracking_float_cols].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unncessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutting_skid = rutting_skid[rutting_skid_float_cols + rutting_skid_index_cols]\n",
    "structure = structure[structure_index_cols + structure_float_cols + structure_string_cols]\n",
    "traffic = traffic[traffic_index_cols + traffic_string_cols + traffic_float_cols]\n",
    "carriageway = carriageway[carriageway_index_cols + carriageway_float_cols + carriageway_string_cols]\n",
    "pavement_layer = pavement_layer[pavement_layer_index_cols + pavement_layer_float_cols + pavement_layer_string_cols]\n",
    "deflection_cracking = deflection_cracking[deflection_cracking_index_cols + deflection_cracking_float_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fixed-length (100m) index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_to_fixed_section(df, fixed_length: float=100):\n",
    "    split_df = df.copy()\n",
    "    split_df = split_df.reset_index(drop=True)\n",
    "\n",
    "    split_df['Start_Index'] = (split_df['Start'] // fixed_length)\n",
    "    split_df['End_Index'] = (split_df['End']) // fixed_length - (split_df['End'] % fixed_length == 0)\n",
    "    split_df.loc[:, 'Duplicate_Count'] = (split_df['End_Index'] - split_df['Start_Index'] + 1) # how many fixed-length sections does this contain?\n",
    "    split_df = split_df.loc[split_df.index.repeat(split_df['Duplicate_Count'])] # duplicate original section to the number of fixed-length it contains\n",
    "    split_df = split_df.reset_index().rename(columns={'index': 'position'})\n",
    "\n",
    "    # assign column matching position with the earliest index with that position\n",
    "    index_position_lookup = split_df.drop_duplicates(subset=['position'], keep='first')['position'].reset_index()\n",
    "    split_df = split_df.set_index('position')\n",
    "    split_df.loc[:, 'original_position'] = index_position_lookup.set_index('position')['index']\n",
    "    split_df = split_df.reset_index()\n",
    "    split_df.loc[:, 'fixed_length_Index'] = split_df['Start_Index'] + split_df.index - split_df['original_position']\n",
    "    split_df = split_df.drop(columns=['position', 'original_position', 'Start_Index', 'End_Index', 'Duplicate_Count'])\n",
    "\n",
    "    # calculate length contribution\n",
    "    split_df['fixed_length_Start'] = split_df['fixed_length_Index'] * fixed_length\n",
    "    split_df['fixed_length_End'] = split_df['fixed_length_Start'] + fixed_length\n",
    "    split_df['Length_Contribution'] = split_df[['End', 'fixed_length_End']].min(axis=1) - split_df[['Start', 'fixed_length_Start']].max(axis=1)\n",
    "\n",
    "    # make sure newly minted start ends are used as index instead of the old ones\n",
    "    split_df.drop(columns=['fixed_length_Index', 'Start', 'End'], inplace=True)\n",
    "    split_df.rename(columns={'fixed_length_Start': 'Start', 'fixed_length_End': 'End'}, inplace=True)\n",
    "\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weighted_mode(group_df, cat_col):\n",
    "    all_weights = group_df.groupby([cat_col])[f'weight_{cat_col}'].sum()\n",
    "    try:\n",
    "        return all_weights.idxmax()\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def group_fixedlength_and_interpolate(df: pd.DataFrame, index_cols: list) -> pd.DataFrame:\n",
    "    temp_df = df.copy()\n",
    "    numeric_cols = list(set(temp_df.select_dtypes('number').columns) - set(index_cols).union({'Length_Contribution'}))\n",
    "    object_cols = list(set(temp_df.select_dtypes('object').columns) - set(index_cols).union({'Length_Contribution'}))\n",
    "\n",
    "    res_df = temp_df.drop_duplicates(index_cols).set_index(index_cols)\n",
    "    res_df = res_df.drop(columns=res_df.columns)\n",
    "\n",
    "    # make weights for original sections when going into the fixed-length section\n",
    "    na_mask = temp_df[numeric_cols + object_cols].notna().values\n",
    "    masked_weights = na_mask * temp_df['Length_Contribution'].values.reshape(-1, 1)\n",
    "    weight_cols = [f'weight_{col}' for col in numeric_cols + object_cols]\n",
    "    temp_df.loc[:, weight_cols] = masked_weights\n",
    "    sum_length = temp_df.groupby(index_cols)[weight_cols].transform(np.sum).values\n",
    "    filtered_weights = masked_weights / np.where(sum_length > 0, sum_length, np.nan)\n",
    "\n",
    "    # mean\n",
    "    temp_df.loc[:, numeric_cols] = temp_df[numeric_cols].values * filtered_weights[:, :len(numeric_cols)] \n",
    "    res_df.loc[:, numeric_cols] = temp_df.groupby(index_cols)[numeric_cols].sum(min_count=1)\n",
    "\n",
    "    # mode\n",
    "    for j, obj_col in enumerate(object_cols):\n",
    "        sum_weight = temp_df.groupby(index_cols + [obj_col])[f'weight_{obj_col}'].sum()\n",
    "        res_df.loc[:, obj_col] = sum_weight.reset_index().set_index([obj_col]).groupby(index_cols)[f'weight_{obj_col}'].idxmax()\n",
    "\n",
    "    del temp_df\n",
    "    return res_df.reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "NZTA_DATADIR = Path(DATA_DIR) / 'interim' / 'NZTA'\n",
    "\n",
    "cut_structure = group_fixedlength_and_interpolate(cast_to_fixed_section(structure, 100), index_cols=structure_index_cols)\n",
    "cut_structure.to_csv(NZTA_DATADIR / '100m_Surface_Structure_new.csv', index=False)\n",
    "cut_traffic = group_fixedlength_and_interpolate(cast_to_fixed_section(traffic, 100), index_cols=traffic_index_cols)\n",
    "cut_traffic.to_csv(NZTA_DATADIR / '100m_Traffic_new.csv', index=False)\n",
    "cut_rutting_skid = group_fixedlength_and_interpolate(cast_to_fixed_section(rutting_skid, 100), index_cols=rutting_skid_index_cols)\n",
    "cut_rutting_skid.to_csv(NZTA_DATADIR / '100m_Rutting_Skid_new.csv', index=False)\n",
    "cut_carriageway = group_fixedlength_and_interpolate(cast_to_fixed_section(carriageway, 100), index_cols=carriageway_index_cols)\n",
    "cut_carriageway.to_csv(NZTA_DATADIR / '100m_Carriageway_new.csv', index=False)\n",
    "cut_pavement_layer = group_fixedlength_and_interpolate(cast_to_fixed_section(pavement_layer, 100), index_cols=pavement_layer_index_cols)\n",
    "cut_pavement_layer.to_csv(NZTA_DATADIR / '100m_Pavement_Layer_new.csv', index=False)\n",
    "cut_deflection_cracking = group_fixedlength_and_interpolate(cast_to_fixed_section(deflection_cracking, 100), index_cols=deflection_cracking_index_cols)\n",
    "cut_deflection_cracking.to_csv(NZTA_DATADIR / '100m_Deflection_Cracking_new.csv', index=False)\n",
    "\n",
    "end = time()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('austroads_taskA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8558eca60468214515578ef8dc9d1a3cd923df7ae0c7c3b68d36aadcc2987ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
