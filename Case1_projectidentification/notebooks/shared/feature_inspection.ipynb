{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src='../../img/WSP_red.png' style='height: 95px; float: left' alt='WSP Logo'/>\n",
    "<img src='../../img/austroads.png' style='height: 115px; float: right' alt='Client Logo'/>\n",
    "</div>\n",
    "<center><h2>AAM6201 Development of Machine-Learning Decision-Support tools for Pavement Asset Management<br>Case Study 1: Project Identification</h2></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic command to autoreload changes in src\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import shap\n",
    "\n",
    "from src.visualization import plot_metric\n",
    "from src import util\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch, Rectangle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import DATA_DIR\n",
    "\n",
    "report_dir = DATA_DIR.parent / 'reports' / 'raw_results'\n",
    "model_dir = DATA_DIR.parent / 'models' / 'trained'\n",
    "\n",
    "# Distribution of train labels vs predicted labels on transfer vs predicted labels on valid\n",
    "from data import DATA_DIR\n",
    "from itertools import product\n",
    "import pickle\n",
    "\n",
    "SUFFIX = 'even_split'\n",
    "juris = ['MRWA', 'NSW', 'NZTA', 'VIC']\n",
    "prefixes = ['final'] * 4\n",
    "suffixes = [SUFFIX] * 4\n",
    "\n",
    "model_dict = {\n",
    "    juri.replace('TA', '').replace('MR', ''): {\n",
    "        'models': {\n",
    "            'XGB': None,\n",
    "            'LR': None\n",
    "        },\n",
    "        'prediction_columns': None\n",
    "    } for juri in juris \n",
    "}\n",
    "\n",
    "for train_name, prefix, suffix in zip(juris, prefixes, suffixes):\n",
    "    juri_name = train_name.replace('TA', '').replace('MR', '')\n",
    "    model_dir = DATA_DIR.parent / 'models' / 'trained' / train_name / f'{train_name.lower()}_{prefix}_{suffix}_dir'\n",
    "    for model_type in ['XGB', 'LR']:\n",
    "        if train_name == 'MRWA' and model_type == 'LR':\n",
    "            continue\n",
    "        with open(model_dir / f'train_{model_type}_timehorizon_{train_name.lower()}_{prefix}_{suffix}.pkl', 'rb') as f:\n",
    "            model_dict[juri_name]['models'][model_type] = pickle.load(f)\n",
    "    with open(model_dir  / f'train_labels_columns_{train_name.lower()}_{prefix}_{suffix}.pkl', 'rb') as f:\n",
    "        model_dict[juri_name]['prediction_columns'] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import util\n",
    "from data import DATA_DIR\n",
    "\n",
    "train_flattened_mrwa_labels = util.load_data(DATA_DIR / 'processed' / 'MRWA' / 'mrwa_final' / 'train_flattened_labels_mrwa_final.csv', header=[0, 1])\n",
    "train_flattened_nzta_labels = util.load_data(DATA_DIR / 'processed' / 'NZTA' / 'nzta_final' / 'train_flattened_labels_nzta_final.csv', header=[0, 1])\n",
    "valid_flattened_mrwa_labels = util.load_data(DATA_DIR / 'processed' / 'MRWA' / 'mrwa_final' / 'valid_flattened_labels_mrwa_final.csv', header=[0, 1])\n",
    "valid_flattened_nzta_labels = util.load_data(DATA_DIR / 'processed' / 'NZTA' / 'nzta_final' / 'valid_flattened_labels_nzta_final.csv', header=[0, 1])\n",
    "\n",
    "train_flattened_mrwa = util.load_data(DATA_DIR / 'processed' / 'MRWA' / 'mrwa_final' / 'train_flattened_data_mrwa_final_no_offset.csv')\n",
    "train_flattened_nzta = util.load_data(DATA_DIR / 'processed' / 'NZTA' / 'nzta_final' / 'train_flattened_data_nzta_final_no_offset.csv')\n",
    "valid_flattened_mrwa = util.load_data(DATA_DIR / 'processed' / 'MRWA' / 'mrwa_final' / 'valid_flattened_data_mrwa_final_no_offset.csv')\n",
    "valid_flattened_nzta = util.load_data(DATA_DIR / 'processed' / 'NZTA' / 'nzta_final' / 'valid_flattened_data_nzta_final_no_offset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flattened_nsw = util.load_data(DATA_DIR / 'processed' / 'NSW' / 'final' / 'train_all.csv')\n",
    "train_flattened_nsw_labels = util.load_data(DATA_DIR / 'processed' / 'NSW' / 'final' / 'labels_all.csv', header=[0, 1])\n",
    "train_flattened_vic = util.load_data(DATA_DIR / 'processed' / 'VIC' / 'final' / 'train_all.csv')\n",
    "train_flattened_vic_labels = util.load_data(DATA_DIR / 'processed' / 'VIC' / 'final' / 'labels_all.csv', header=[0, 1])\n",
    "\n",
    "valid_flattened_nsw = util.load_data(DATA_DIR / 'processed' / 'NSW' / 'final' / 'valid_all.csv')\n",
    "valid_flattened_nsw_labels = util.load_data(DATA_DIR / 'processed' / 'NSW' / 'final' / 'valid_labels_all.csv', header=[0, 1])\n",
    "valid_flattened_vic = util.load_data(DATA_DIR / 'processed' / 'VIC' / 'final' / 'valid_all.csv')\n",
    "valid_flattened_vic_labels = util.load_data(DATA_DIR / 'processed' / 'VIC' / 'final' / 'valid_labels_all.csv', header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_map_dict = {\n",
    "    'Treatment within 1 year': 'Year 1',\n",
    "    'Treatment between 1 to 3 years': 'Year 2 - 3',\n",
    "    'Treatment between 3 to 5 years': 'Year 4 - 5',\n",
    "    'Treatment between 5 to 10 years': 'Year 6 - 10',\n",
    "}\n",
    "\n",
    "year_order_dict = {\n",
    "    'Treatment within 1 year': 0.5,\n",
    "    'Treatment between 1 to 3 years': 2, \n",
    "    'Treatment between 3 to 5 years': 4, \n",
    "    'Treatment between 5 to 10 years': 7.5,\n",
    "}\n",
    "\n",
    "treatment_type_order = {\n",
    "    'Resurfacing_SS': 0,\n",
    "    'Resurfacing_AC': 1,\n",
    "    'Major Patching': 2,\n",
    "    'Rehabilitation': 3,\n",
    "    'Retexturing': 4,\n",
    "    'Regulation': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_dir = report_dir.parent / 'figures' / 'feature_inspection' / SUFFIX\n",
    "if save_fig_dir.exists() is False:\n",
    "    save_fig_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def get_magnitude_direction(shap_values_lst: List[float], feature_values_lst: List[float]) -> Tuple[float, float]:\n",
    "    \"\"\"Return the mean of the absolute value of shap coefficients, siginfying the magnitude of their effect,\n",
    "    multiplied by 1 if the values are positively correlated with feature values, else -1\"\"\"\n",
    "    # if the feature has 0 contribution\n",
    "    if np.max(np.abs(shap_values_lst)) < 1e-5:\n",
    "        return 0, 0\n",
    "\n",
    "    try:\n",
    "        with np.errstate(all='raise'):\n",
    "            # corr_coeff_mat = np.corrcoef(\n",
    "            #     shap_values_lst, feature_values_lst\n",
    "            # )\n",
    "            corr_coeff, pval = spearmanr(\n",
    "                shap_values_lst, feature_values_lst\n",
    "            )\n",
    "            return_val = np.mean(np.abs(shap_values_lst)) * (1 if corr_coeff > 0 else - 1)\n",
    "            if pval < 0.05:\n",
    "                corr_coeff_magnitude = np.abs(corr_coeff)\n",
    "            else:\n",
    "                corr_coeff_magnitude = 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Feature name: ', feature_values_lst.name)\n",
    "        print('Sample of feature values: ', np.random.choice(feature_values_lst, size=10))\n",
    "        print('Shap values max abs: ', np.max(np.abs(shap_values_lst)))\n",
    "        print('Sample of shap values: ', np.random.choice(shap_values_lst, size=10))\n",
    "        raise e\n",
    "\n",
    "    return return_val, corr_coeff_magnitude\n",
    "\n",
    "def normalize_uniform(arr: np.ndarray):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.colors import LinearSegmentedColormap \n",
    "\n",
    "juris = ['NZ', 'NSW', 'WA']\n",
    "datasets = [train_flattened_nzta, train_flattened_nsw, train_flattened_mrwa, train_flattened_vic] \n",
    "labels = [train_flattened_nzta_labels, train_flattened_nsw_labels, train_flattened_mrwa_labels, train_flattened_vic_labels]\n",
    "force_redo = []\n",
    "\n",
    "save_name = 'raw_shap_results_pos_background.pkl'\n",
    "if (save_fig_dir / save_name).exists():\n",
    "    with open(save_fig_dir / save_name, 'rb') as f:\n",
    "        raw_shap_result = pickle.load(f)\n",
    "else:\n",
    "    raw_shap_result = {juri: {} for juri in juris} \n",
    "\n",
    "try:\n",
    "    for juri, eval_features, eval_labels in tqdm(zip(juris, datasets, labels), desc='juri', total=len(juris)):\n",
    "        row_dict = {t: i for i, t in enumerate(['Treatment within 1 year', 'Treatment between 1 to 3 years', 'Treatment between 3 to 5 years', 'Treatment between 5 to 10 years'])}\n",
    "        col_dict = {t: i for i, t in enumerate(['Resurfacing_SS', 'Resurfacing_AC', 'Major Patching', 'Rehabilitation'])}\n",
    "        if juri  not in raw_shap_result:\n",
    "            raw_shap_result[juri] = {}\n",
    "        for col_idx, col in enumerate(tqdm(model_dict[juri]['prediction_columns'], desc='Prediction columns')):\n",
    "            if (col[1] not in col_dict) or (col[0] not in row_dict):\n",
    "                continue\n",
    "            elif col not in raw_shap_result[juri]:\n",
    "                raw_shap_result[juri][col] = {}\n",
    "            estimator_idx = np.argwhere(model_dict[juri]['prediction_columns'] == col).flatten()\n",
    "            if estimator_idx.size != 1:\n",
    "                continue\n",
    "            # add to juri dict\n",
    "            if estimator_idx[0] not in raw_shap_result[juri][col]:\n",
    "                raw_shap_result[juri][col][estimator_idx[0]] = {}\n",
    "            # calculate shap values for each model\n",
    "            shap_values_lst = []\n",
    "            for model_idx, model in enumerate(model_dict[juri]['models']['XGB']):\n",
    "                if (model_idx not in raw_shap_result[juri][col][estimator_idx[0]]) or (raw_shap_result[juri][col][estimator_idx[0]][model_idx] is None) or juri in force_redo:\n",
    "                    explainer = shap.TreeExplainer(\n",
    "                        model.estimators_[estimator_idx[0]], \n",
    "                        data=(\n",
    "                            eval_features[eval_labels[col] == 1] if 'pos_background' in save_name else\n",
    "                            eval_features\n",
    "                        ),\n",
    "                        model_output='probability',\n",
    "                        feature_perturbation='interventional'\n",
    "                    )\n",
    "                    # shap values show marginal (average value if all else equal) effect of each feature on the probability of 'positive class' being true \n",
    "                    shap_values = explainer.shap_values(eval_features)\n",
    "                    raw_shap_result[juri][col][estimator_idx[0]][model_idx] = shap_values\n",
    "            with open(save_fig_dir / save_name, 'wb') as f:\n",
    "                pickle.dump(raw_shap_result, f)\n",
    "except Exception as e:\n",
    "    with open(save_fig_dir / save_name, 'wb') as f:\n",
    "        pickle.dump(raw_shap_result, f)\n",
    "    raise e\n",
    "finally:\n",
    "    with open(save_fig_dir / save_name, 'wb') as f:\n",
    "        pickle.dump(raw_shap_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load computed shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pos_background = True \n",
    "with open(save_fig_dir / ('raw_shap_results' + ('_pos_background' if use_pos_background else '_all') + '.pkl'), 'rb') as f:\n",
    "    raw_shap_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beeswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from src.visualization.shap_beeswarm import shap_summary\n",
    "from matplotlib.ticker import FixedLocator \n",
    "from matplotlib.colors import LinearSegmentedColormap \n",
    "\n",
    "juris = ['NZ', 'NSW', 'WA']\n",
    "datasets = [train_flattened_nzta, train_flattened_nsw, train_flattened_mrwa] \n",
    "labels = [train_flattened_nzta_labels, train_flattened_nsw_labels, train_flattened_mrwa_labels]\n",
    "colors = ['red', 'orange','blue']\n",
    "\n",
    "force_redo = []\n",
    "\n",
    "for juri, c, eval_features, eval_labels in tqdm(zip(juris, colors, datasets, labels), desc='juri', total=len(juris)):\n",
    "    row_dict = {t: i for i, t in enumerate(['Treatment within 1 year', 'Treatment between 1 to 3 years', 'Treatment between 3 to 5 years', 'Treatment between 5 to 10 years'])}\n",
    "    col_dict = {t: i for i, t in enumerate(['Resurfacing_SS', 'Resurfacing_AC', 'Major Patching', 'Rehabilitation'])}\n",
    "\n",
    "    fig = plt.figure(figsize=(36, 36))\n",
    "\n",
    "    for col_idx, col in enumerate(tqdm(model_dict[juri]['prediction_columns'], desc='Prediction columns')):\n",
    "        if (col[1] not in col_dict) or (col[0] not in row_dict):\n",
    "            continue\n",
    "        ax = plt.subplot(4, 4, row_dict[col[0]] * 4 + col_dict[col[1]] + 1)\n",
    "        plt.sca(ax)\n",
    "        # find model corresponding to prediction column\n",
    "        estimator_idx = np.argwhere(model_dict[juri]['prediction_columns'] == col).flatten()\n",
    "        if estimator_idx.size != 1:\n",
    "            continue\n",
    "        # calculate shap values for each model\n",
    "        shap_values_lst = []\n",
    "        for model_idx, model in enumerate(model_dict[juri]['models']['XGB']):\n",
    "            shap_values = raw_shap_result[juri][col][estimator_idx[0]][model_idx]\n",
    "            shap_values_lst.append(shap_values)\n",
    "\n",
    "        # get mean shap values for each feature\n",
    "        shap_values_arr = np.array(shap_values_lst).mean(axis=0) # shape: (len(eval_features), len(features))\n",
    "\n",
    "        shap_summary(\n",
    "            shap_values=shap_values_arr,\n",
    "            features=eval_features.rename(columns={\n",
    "                col: col.replace('_df0', '').replace('|idx=0', '') for col in eval_features.columns\n",
    "            }) if juri != 'VIC' else eval_features,\n",
    "            sort=False,\n",
    "            show=False,\n",
    "            color_bar_label='Feature Value',\n",
    "        )\n",
    "\n",
    "        plt.title(\n",
    "            f'{year_map_dict[col[0]]} - {col[1]}',\n",
    "            fontsize=18\n",
    "        )\n",
    "\n",
    "    inner_dir = save_fig_dir / ('beeswarm_joined' + ('_pos_background' if use_pos_background else ''))\n",
    "    if not inner_dir.exists(): inner_dir.mkdir()\n",
    "    plt.suptitle(\n",
    "        f'{juri}\\nDistribution of SHAP values colored by normalized feature values'\\\n",
    "        + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "        fontsize=25\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.savefig(inner_dir / (f'shap_{juri}_beeswarm' + ('_pos_background' if use_pos_background else '') + '.jpg'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman SHAP correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.ticker import FixedLocator\n",
    "from matplotlib.colors import LinearSegmentedColormap \n",
    "\n",
    "juris = ['NZ', 'NSW', 'WA']\n",
    "datasets = [train_flattened_nzta, train_flattened_nsw, train_flattened_mrwa] \n",
    "labels = [train_flattened_nzta_labels, train_flattened_nsw_labels, train_flattened_mrwa_labels]\n",
    "colors = ['red', 'orange', 'blue']\n",
    "forced_redo = []\n",
    "\n",
    "for juri, c, eval_features, eval_labels in tqdm(zip(juris, colors, datasets, labels), desc='juri', total=len(juris)):\n",
    "    row_dict = {t: i for i, t in enumerate(['Treatment within 1 year', 'Treatment between 1 to 3 years', 'Treatment between 3 to 5 years', 'Treatment between 5 to 10 years'])}\n",
    "    col_dict = {t: i for i, t in enumerate(['Resurfacing_SS', 'Resurfacing_AC', 'Major Patching', 'Rehabilitation'])}\n",
    "\n",
    "    fig = plt.figure(figsize=(36, 36))\n",
    "    for col_idx, col in enumerate(tqdm(model_dict[juri]['prediction_columns'], desc='Prediction columns')):\n",
    "        if (col[1] not in col_dict) or (col[0] not in row_dict):\n",
    "            continue\n",
    "        ax = plt.subplot(4, 4, row_dict[col[0]] * 4 + col_dict[col[1]] + 1)\n",
    "        col_name = f\"{col[0].replace('Treatment ', '')} - {col[1].replace('Resurfacing_', '')}\" \n",
    "        plt.sca(ax)\n",
    "        # find model corresponding to prediction column\n",
    "        estimator_idx = np.argwhere(model_dict[juri]['prediction_columns'] == col).flatten()\n",
    "        if estimator_idx.size != 1:\n",
    "            continue\n",
    "        # calculate shap values for each model\n",
    "        shap_values_lst = []\n",
    "        for model_idx, model in enumerate(model_dict[juri]['models']['XGB']):\n",
    "            shap_values = raw_shap_result[juri][col][estimator_idx[0]][model_idx]\n",
    "            shap_values_lst.append(shap_values)\n",
    "        # get mean shap values for each feature\n",
    "        shap_values_arr = np.array(shap_values_lst).mean(axis=0) # shape: (len(eval_features), len(features))\n",
    "        shap_values_all, corr_coef_mag_all = zip(\n",
    "            *[get_magnitude_direction(shap_values_arr[:, i], eval_features.iloc[:, i]) for i in range(eval_features.shape[1])]\n",
    "        )\n",
    "        # make linear colormap from white - juri color\n",
    "        cmap = LinearSegmentedColormap.from_list('', colors=['white', c])\n",
    "        # plot bar plot\n",
    "        ax.bar(\n",
    "            x=np.arange(len(eval_features.columns)), \n",
    "            height=corr_coef_mag_all,\n",
    "            color=cmap([1 if c > 0.5 else 0.5 for c in corr_coef_mag_all])\n",
    "        )\n",
    "        ax.grid()\n",
    "        ax.set_ylabel('|Coefficient Magnitude|')\n",
    "        ax.set_title(f'{year_map_dict[col[0]]} - {col[1]}')\n",
    "        ax.xaxis.set_major_locator(FixedLocator(np.arange(len(eval_features.columns))))\n",
    "        ax.xaxis.set_tick_params(direction='out')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xticklabels(\n",
    "            [col.replace(\"_df0\", \"\").replace(\"|idx=0\", \"\") for col in eval_features.columns] if juri != 'VIC' else eval_features.columns, \n",
    "            rotation=45, ha='right'\n",
    "        )\n",
    "        threshold_line = ax.axhline(y=0.5, label='Threshold', c='r', linestyle='--')\n",
    "        ax.legend(handles=[threshold_line])\n",
    "\n",
    "    fig.suptitle(\n",
    "        f'{juri} - Spearman correlation magnitude between\\nSHAP values and feature values'\\\n",
    "        + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "        fontsize=25,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    inner_dir = save_fig_dir / 'spearman_only'\n",
    "    if not inner_dir.exists(): inner_dir.mkdir()\n",
    "    plt.savefig(inner_dir / f'corr_{juri}_new.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Effect direction check with known relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap aggreement with known relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flags_from_relationships(known_r: float, shap_r: float, corr_r: float, data_r: float):\n",
    "    # this goes in priority level\n",
    "    if known_r == 0:\n",
    "        consistency_flag = 'No expected relationship'\n",
    "    else:\n",
    "        consistency_flag = 'Consistent with SME' if np.sign(known_r) == np.sign(shap_r) else 'Inconsistent with SME'\n",
    "    \n",
    "    correlation_flag = ('Strong ' if corr_r >= 0.5 else 'Weak ') + 'correlation'\n",
    "\n",
    "    if data_r == 0:\n",
    "        data_flag = 'No expected relationship from data'\n",
    "    else:\n",
    "        data_flag = 'Consistent with data' if np.sign(data_r) == np.sign(shap_r) else 'Inconsistent with data'\n",
    "\n",
    "    return consistency_flag, correlation_flag, data_flag\n",
    "\n",
    "from tqdm import tqdm\n",
    "known_relationships = pd.read_csv(DATA_DIR.parent / 'references' / 'known_relationships.csv')\n",
    "\n",
    "juris = ['NZ', 'NSW', 'WA']\n",
    "datasets = [train_flattened_nzta, train_flattened_nsw, train_flattened_mrwa] \n",
    "labels = [train_flattened_nzta_labels, train_flattened_nsw_labels, train_flattened_mrwa_labels]\n",
    "colors = ['red', 'orange','blue']\n",
    "result = []\n",
    "total = 0\n",
    "\n",
    "time_set = {'Treatment between 3 to 5 years', 'Treatment between 1 to 3 years', 'Treatment within 1 year', 'Treatment between 5 to 10 years'}\n",
    "treat_set = {'Resurfacing_SS', 'Resurfacing_AC', 'Rehabilitation'}\n",
    "\n",
    "for juri, c, eval_features, eval_labels in tqdm(zip(juris, colors, datasets, labels), desc='juri', total=len(juris)):\n",
    "    for col_idx, col in enumerate(tqdm(model_dict[juri]['prediction_columns'], desc='Prediction columns')):\n",
    "        # find model corresponding to prediction column\n",
    "        estimator_idx = np.argwhere(model_dict[juri]['prediction_columns'] == col).flatten()\n",
    "        if (estimator_idx.size != 1) or (col[0] not in time_set) or (col[1] not in treat_set):\n",
    "            continue\n",
    "        shap_values_lst = []\n",
    "        for model_idx, model in enumerate(model_dict[juri]['models']['XGB']):\n",
    "            shap_values = raw_shap_result[juri][col][estimator_idx[0]][model_idx]\n",
    "            shap_values_lst.append(shap_values)\n",
    "\n",
    "        # get mean shap values for each feature\n",
    "        shap_values_arr = np.array(shap_values_lst).mean(axis=0) # shape: (len(eval_features), len(features))\n",
    "        shap_values_all, corr_coef_mag_all = zip(\n",
    "            *[get_magnitude_direction(shap_values_arr[:, i], eval_features.iloc[:, i]) for i in range(eval_features.shape[1])]\n",
    "        )\n",
    "\n",
    "        for i, feature in enumerate(eval_features):\n",
    "            # get sign of known relationship\n",
    "            known_rs = known_relationships.loc[\n",
    "                known_relationships['category'].apply(lambda f: f in feature.lower()),\n",
    "                col[1].lower()\n",
    "            ]\n",
    "            if len(known_rs) > 0:\n",
    "                assert known_rs.nunique() == 1\n",
    "                known_r = known_rs.iloc[0]\n",
    "                shap_r = shap_values_all[i]\n",
    "                corr_r = corr_coef_mag_all[i]\n",
    "\n",
    "                data_r, p_value = spearmanr(eval_features.iloc[:, i], eval_labels[col])\n",
    "                data_r = int(np.sign(data_r) * (p_value < 0.05))\n",
    "\n",
    "                con_flag, corr_flag, data_flag = get_flags_from_relationships(known_r=known_r, shap_r=shap_r, corr_r=corr_r, data_r=data_r)\n",
    "                result.append((juri, col[0], col[1], feature, shap_r, corr_r, con_flag, corr_flag, data_flag, known_r, int(np.sign(shap_r)), data_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result, columns=['juri', 'Treatment Time', 'Treatment Type', 'Feature', 'Mean Abs SHAP', 'Correlation Magnitude', 'Consistency Flag', 'Correlation Flag', 'Consistency Data Flag', 'Known effect', 'Model effect', 'Data effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_explained_simple = result_df[\n",
    "    ((result_df['Consistency Flag'] == 'Inconsistent with SME') & (result_df['Correlation Flag'] == 'Strong correlation')) &\\\n",
    "    ((result_df['Known effect'] != result_df['Data effect']) & (result_df['Data effect'] != 0))\n",
    "]\n",
    "correct_unexplained_simple = result_df[\n",
    "    ((result_df['Consistency Flag'] == 'Consistent with SME') & (result_df['Correlation Flag'] == 'Strong correlation')) &\\\n",
    "    ((result_df['Known effect'] != result_df['Data effect']) & (result_df['Data effect'] != 0))\n",
    "]\n",
    "\n",
    "print(\"Out of strongly correlated effects...\")\n",
    "print(\"Number of relationships which is inconsistent with SME: {}\".format(((result_df['Consistency Flag'] == 'Inconsistent with SME') & (result_df['Correlation Flag'] == 'Strong correlation')).sum()))\n",
    "print(\"Number of relationship which is inconsistent with SME but consistent with data: {}\".format(len(wrong_explained_simple)))\n",
    "print(\"Number of relationship which is consistent with SME but inconsistent with data: {}\".format(len(correct_unexplained_simple)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot heatmap for each juri-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "aliceblue = np.array([0.9411764705882353, 0.9725490196078431, 1.0, 1.0])\n",
    "red = np.array([167 / 255, 35 / 255, 38 / 255, 1])\n",
    "pale_red = np.array([167 / 255, 35 / 255, 38 / 255, 0.1])\n",
    "green = np.array([125 / 255, 148 / 255, 52 / 255, 1])\n",
    "pale_green = np.array([125 / 255, 148 / 255, 52 / 255, 0.1])\n",
    "\n",
    "# collector variables\n",
    "f_to_i = {\n",
    "    'Weak correlation and Inconsistent with SME': 0,\n",
    "    'Strong correlation and Inconsistent with SME': 1,\n",
    "    'Weak correlation and Consistent with SME': 2,\n",
    "    'Strong correlation and Consistent with SME': 3,\n",
    "    'Strong correlation and No expected relationship': 4,\n",
    "    'Weak correlation and No expected relationship': 5,\n",
    "}\n",
    "\n",
    "c_array = np.array([pale_red, red, pale_green, green, aliceblue, aliceblue])\n",
    "\n",
    "\n",
    "def plot_heatmap_effect_compar(df: pd.DataFrame, ax: plt.Axes):\n",
    "    juri = df['juri'].iloc[0]\n",
    "    year_type = df['Treatment Time'].iloc[0]\n",
    "    df['Flag'] = df['Correlation Flag'] + ' and ' + df['Consistency Flag']\n",
    "    # generate pivoted map\"\n",
    "    flag_mat = df.pivot(index='Feature', columns='Treatment Type', values='Flag')\n",
    "    flag_mat = flag_mat.replace(f_to_i)\n",
    "    effect_mat = df.pivot(index='Feature', columns='Treatment Type', values='Known effect')\n",
    "    annot_mat = np.zeros_like(effect_mat).astype(str)\n",
    "    annot_mat[np.where(effect_mat < 0)] = '▼'\n",
    "    annot_mat[np.where(effect_mat > 0)] = '▲'\n",
    "    annot_mat[np.where(effect_mat == 0)] = ''\n",
    "\n",
    "    discrete_cmap = ListedColormap([pale_red, red, pale_green, green, 'aliceblue', 'aliceblue'], name='discrete_cmap') # color correspond to flag index\n",
    "\n",
    "    # plot\n",
    "    ax.imshow(\n",
    "        c_array[flag_mat],\n",
    "        aspect='auto'\n",
    "    )\n",
    "    ax.set_xticks(np.arange(0, flag_mat.shape[1], 1))\n",
    "    ax.set_yticks(np.arange(0, flag_mat.shape[0], 1))\n",
    "\n",
    "    # Labels for major ticks\n",
    "    ax.set_xticklabels(list(flag_mat.columns))\n",
    "    ax.set_yticklabels(list(flag_mat.index))\n",
    "\n",
    "    # Minor ticks\n",
    "    ax.set_xticks(np.arange(-.5, flag_mat.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, flag_mat.shape[0], 1), minor=True)\n",
    "    # make invisible\n",
    "    ax.tick_params(axis='x', which='minor', length=0)\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "\n",
    "    # Gridlines based on minor ticks\n",
    "    ax.grid(which='minor', color='white', linestyle='-', linewidth=1)\n",
    "    # remove border\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    plt.title(f'{juri} | {year_type}')\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(None)\n",
    "\n",
    "    color_legend = plt.legend(\n",
    "        title='Color Legend',\n",
    "        handles=[Patch(color=discrete_cmap(i)) for i in range(5)],\n",
    "        labels=['Weak correlation and Inconsistent with SME',\n",
    "            'Strong correlation and Inconsistent with SME',\n",
    "            'Weak correlation and Consistent with SME',\n",
    "            'Strong correlation and Consistent with SME',\n",
    "            'No expected relationship',\n",
    "        ],\n",
    "        bbox_to_anchor=(0.5, -0.1),\n",
    "    ) \n",
    "    up_arrow = ax.scatter([], [], c='black', marker=u'$\\u25b2$', s=150, label='SME expects Positive correlation')\n",
    "    low_arrow = ax.scatter([], [], c='black', marker=u'$\\u25bc$', s=150, label='SME expects Negative correlation')\n",
    "    up_arrow_model = ax.scatter([], [], c='red', marker=u'$\\u25b2$', s=150, label='Model expects Positive correlation')\n",
    "    low_arrow_model = ax.scatter([], [], c='red', marker=u'$\\u25bc$', s=150, label='Model expects Negative correlation')\n",
    "    cross = Patch(facecolor='white', fill=False, hatch='xxxx', edgecolor='black', label='SME inconsistent with data')\n",
    "    ax.legend(handles=[up_arrow, low_arrow, up_arrow_model, low_arrow_model, cross], title='Icon Legend', bbox_to_anchor=(1, -0.1))\n",
    "    # ax.legend(title='Icon Legend', bbox_to_anchor=(1, -0.1))\n",
    "    ax.add_artist(color_legend)\n",
    "\n",
    "    # add crosses to denote correlation is supported/ unsupported with data \n",
    "    df.loc[\n",
    "        (df['Known effect'] != df['Data effect']) & (df['Data effect'] != 0) &\\\n",
    "        (df['Known effect'] != 0) & (df['Correlation Flag'] == 'Strong correlation'),\n",
    "        'Special consideration'\n",
    "    ] = True\n",
    "    cross_loc = np.where(df.pivot(index='Feature', columns='Treatment Type', values='Special consideration') == True) \n",
    "    for start, end in zip(cross_loc[0], cross_loc[1]):\n",
    "        ax.add_patch(Rectangle((end - 0.5, start - 0.5), 1, 1, fill=False, hatch='x', edgecolor='black'))\n",
    "    \n",
    "    # add red arrows \n",
    "    model_mat = df.pivot(index='Feature', columns='Treatment Type', values='Model effect')\n",
    "    no_known_annot = np.zeros_like(effect_mat).astype(str)\n",
    "    no_known_annot[np.where((flag_mat == 4) & (model_mat > 0))] = '▲' \n",
    "    no_known_annot[np.where((flag_mat == 4) & (model_mat < 0))] = '▼' \n",
    "    no_known_annot[np.where((flag_mat != 4) | (model_mat == 0))] = '' \n",
    "    height, width = no_known_annot.shape\n",
    "    xpos = np.arange(width)\n",
    "    ypos = np.arange(height)\n",
    "    for i_xpos, x in enumerate(xpos):\n",
    "        for j_ypos, y in enumerate(ypos):\n",
    "            val_no_known = no_known_annot[j_ypos][i_xpos]\n",
    "            annot_val = annot_mat[j_ypos][i_xpos]\n",
    "            if val_no_known == '': \n",
    "                text_color = \"black\"\n",
    "                text_kwargs = dict(color=text_color, ha=\"center\", va=\"center\")\n",
    "                ax.text(x, y, annot_val, **text_kwargs)\n",
    "            else:\n",
    "                text_color = \"red\"\n",
    "                text_kwargs = dict(color=text_color, ha=\"center\", va=\"center\")\n",
    "                ax.text(x, y, val_no_known, **text_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 38))\n",
    "juris = ['NZ', 'WA', 'NSW']\n",
    "\n",
    "for i_juri, juri in enumerate(juris):\n",
    "    # process result for each juri\n",
    "    juri_result = result_df[result_df['juri'] == juri].copy()\n",
    "    juri_result.loc[:, 'Treatment Time'] = juri_result['Treatment Time'].replace(year_map_dict)\n",
    "    juri_result.loc[:, 'Feature'] = juri_result['Feature'].apply(lambda x: x.replace('|idx=0', '').replace('_df0', ''))\n",
    "\n",
    "    for j_year_type, year_type in enumerate(['Year 1', 'Year 2 - 3', 'Year 4 - 5', 'Year 6 - 10']):\n",
    "        df = juri_result[juri_result['Treatment Time'] == year_type].copy()\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        ax = plt.subplot(4, 3, 1 + (i_juri + j_year_type * 3))\n",
    "        plot_heatmap_effect_compar(df, ax)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Comparison between modelled univariate feature effects and expert (SME) expectations'\\\n",
    "   + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "    fontsize=16\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.98], h_pad=7)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'for_each_time{\"_pos_background\" if use_pos_background else \"_all_background\"}_new.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get plot for each jurisdiction independently\n",
    "juris = ['NZ', 'WA', 'NSW']\n",
    "\n",
    "for i_juri, juri in enumerate(juris):\n",
    "    # process result for each juri\n",
    "    juri_result = result_df[result_df['juri'] == juri].copy()\n",
    "    juri_result.loc[:, 'Treatment Time'] = juri_result['Treatment Time'].replace(year_map_dict)\n",
    "    juri_result.loc[:, 'Feature'] = juri_result['Feature'].apply(lambda x: x.replace('|idx=0', '').replace('_df0', ''))\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "    for j_year_type, year_type in enumerate(['Year 1', 'Year 2 - 3', 'Year 4 - 5', 'Year 6 - 10']):\n",
    "        df = juri_result[juri_result['Treatment Time'] == year_type].copy()\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        ax = plt.subplot(2, 2, 1 + j_year_type)\n",
    "        plot_heatmap_effect_compar(df, ax)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f'Comparison between modelled univariate feature effects and expert (SME) expectations - Jurisdiction: {juri}'\\\n",
    "        + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "        fontsize=16\n",
    "    )\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.98], h_pad=7)\n",
    "\n",
    "    inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "    if not inner_dir.exists():\n",
    "        inner_dir.mkdir()\n",
    "    plt.savefig(inner_dir / f'{juri}{\"_pos_background\" if use_pos_background else \"_all_background\"}_new.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example juri - year pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process result for each juri\n",
    "juri = 'NZ'\n",
    "year_type = 'Treatment between 1 to 3 years'\n",
    "juri_result = result_df[(result_df['juri'] == juri) & (result_df['Treatment Time'] == year_type)].copy()\n",
    "juri_result.loc[:, 'Treatment Time'] = juri_result['Treatment Time'].replace(year_map_dict)\n",
    "juri_result.loc[:, 'Feature'] = juri_result['Feature'].apply(lambda x: x.replace('|idx=0', '').replace('_df0', ''))\n",
    "fig = plt.figure(figsize=(10, 12))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plot_heatmap_effect_compar(juri_result, ax)\n",
    "plt.suptitle(\n",
    "    f'Comparison between modelled univariate feature effects and expert (SME) expectations'\\\n",
    "  + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance')\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.98], h_pad=7)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'heatmap_example.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot heatmap for strength of shap effect for each juri year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "from itertools import product\n",
    "\n",
    "fig = plt.figure(figsize=(23, 36))\n",
    "juris = ['NZ', 'WA', 'NSW']\n",
    "\n",
    "continous_cmap = {\n",
    "    'NZ': LinearSegmentedColormap.from_list(name='austroads', colors=['#FFFFFF', 'tab:red']),\n",
    "    'WA': LinearSegmentedColormap.from_list(name='austroads', colors=['#FFFFFF', 'tab:blue']),\n",
    "    'NSW': LinearSegmentedColormap.from_list(name='austroads', colors=['#FFFFFF', 'tab:orange']),\n",
    "}\n",
    "\n",
    "for i_juri, juri in enumerate(juris):\n",
    "    # process result for each juri\n",
    "    juri_result = result_df[result_df['juri'] == juri].drop(columns=['juri']).copy()\n",
    "    juri_result.loc[:, 'Treatment Time'] = juri_result['Treatment Time'].replace(year_map_dict)\n",
    "    juri_result.loc[:, 'Feature'] = juri_result['Feature'].apply(lambda x: x.replace('|idx=0', '').replace('_df0', ''))\n",
    "\n",
    "    for j_year_type, year_type in enumerate(['Year 1', 'Year 2 - 3', 'Year 4 - 5', 'Year 6 - 10']):\n",
    "        df = juri_result[juri_result['Treatment Time'] == year_type].copy()\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        # generate pivoted map\n",
    "        value_mat = df.pivot(index='Feature', columns='Treatment Type', values='Mean Abs SHAP')\n",
    "        value_mat = (value_mat - value_mat.min(axis=0)) / (value_mat.max(axis=0) - value_mat.min(axis=0))\n",
    "        effect_mat = df.pivot(index='Feature', columns='Treatment Type', values='Known effect')\n",
    "        \n",
    "        # plot\n",
    "        ax : plt.Axes\n",
    "        ax = plt.subplot(4, 3, 1 + (i_juri + j_year_type * 3))\n",
    "        sns.heatmap(\n",
    "            value_mat,\n",
    "            cmap=continous_cmap[juri],\n",
    "            linecolor='white', linewidth=1,\n",
    "            fmt='',\n",
    "            cbar=True,\n",
    "            ax=ax,\n",
    "        )\n",
    "        cbar = ax.collections[0].colorbar\n",
    "        cbar.set_ticks([0.1, 0.8])\n",
    "        cbar.set_ticklabels(['low', 'high'])\n",
    "        cbar.set_label('Normalised feature effect')\n",
    "        plt.title(f'{juri} | {year_type}')\n",
    "        plt.xlabel(None)\n",
    "        plt.ylabel(None)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Normalised feature importances'\\\n",
    "   + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "    fontsize=25,\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.98], h_pad=7)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'for_each_time_strength_effect{\"_pos_background\" if use_pos_background else \"_all_background\"}_new.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot aggregated heatmap over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_years(years):\n",
    "    res = ''\n",
    "    start, end = None, None\n",
    "    for y in years:\n",
    "        if start is None:\n",
    "            start = int(y[0])\n",
    "            end = int(y[-2:])\n",
    "        else:\n",
    "            if int(y[0]) == end + 1:\n",
    "                end = int(y[-2:])\n",
    "            else:\n",
    "                res += (', ' if len(res) > 0 else '') + (f'{start} - {end}' if end > start else f'{start}')\n",
    "                start = int(y[0])\n",
    "                end = int(y[-2:])\n",
    "    return res + (', ' if len(res) > 0 else '') + (f'{start} - {end}' if end > start else f'{start}')\n",
    "\n",
    "        \n",
    "def process_flag_group(group: pd.DataFrame):\n",
    "    \"\"\"Process group of feature effects flag, each group for each treatment type - feature pair by rules\"\"\"\n",
    "    # 1. if there is at least 1 strong incorrect, set flag to incorrect, return number of incorrect, and mean treatment time\n",
    "    # 2. if there is at least 1 no expected relationship, assert ALL are no expected relationship, set flag to no expected relationship\n",
    "    # 3. if all flags are noisy, set flag to noisy\n",
    "    # 4. any other case, set flag to correct\n",
    "    assert group['Known effect'].nunique() == 1\n",
    "    ret = {'Treatment Time': np.nan, 'Flag': None, 'Percent wrong': np.nan, 'Known effect': group['Known effect'].iloc[0], 'Explained': np.nan, 'Model effect': 0}\n",
    "    flags = group['Correlation Flag'] + ' and ' + group['Consistency Flag']\n",
    "    flags = flags.replace('Weak correlation and No expected relationship', 'No expected relationship')\n",
    "    flags = flags.replace('Strong correlation and No expected relationship', 'No expected relationship')\n",
    "    \n",
    "    seen_flags = set(flags)\n",
    "    if ('Strong correlation and Inconsistent with SME' in seen_flags):\n",
    "        ret['Treatment Time'] = 'Year ' + merge_years(sorted(group[group['Consistency Flag'] == 'Inconsistent with SME']['Treatment Time'].str.strip('Year ').to_list()))\n",
    "        # if all the wrong flags have an opposite data effects, set flag to Inconsistent but explained\n",
    "        if len(group[\n",
    "            (flags == 'Strong correlation and Inconsistent with SME') &\\\n",
    "            (group['Known effect'] == group['Data effect'])\n",
    "        ]) == 0:\n",
    "            ret['Flag'] = 'Inconsistent with SME but explained with data'\n",
    "        else:\n",
    "            ret['Flag'] = 'Inconsistent with SME'\n",
    "    elif 'No expected relationship' in seen_flags:\n",
    "        assert len(seen_flags) == 1, \"There cannot be both 'No expected relationship' flag and another flag!\"\n",
    "        ret['Flag'] = 'No expected relationship'\n",
    "        if group.loc[(group['Correlation Flag'] == 'Strong correlation') & (group['Model effect'] != 0), 'Model effect'].nunique() == 1:\n",
    "            ret['Model effect'] = group['Model effect'].max() if group['Model effect'].max() > 0 else -1\n",
    "    elif np.all([flag.startswith('Weak correlation') for flag in seen_flags]):\n",
    "        ret['Flag'] = 'Weak correlation with feature'\n",
    "    else: # at least 1 strong correct, can have multiple weak incorrect\n",
    "        if len(group[\n",
    "            (flags == 'Strong correlation and Consistent with SME') &\\\n",
    "            (group['Known effect'] != group['Data effect'])\n",
    "        ]) == 0:\n",
    "            ret['Flag'] = 'Consistent with SME'\n",
    "        else:\n",
    "            ret['Flag'] = 'Consistent with SME but unsupported with data'\n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(27, 11))\n",
    "juris = ['NZ', 'WA', 'NSW']\n",
    "\n",
    "flag_to_index = {\n",
    "    'Weak correlation with feature': 0,\n",
    "    'Inconsistent with SME': 1,\n",
    "    'Inconsistent with SME but explained with data': 2,\n",
    "    'Consistent with SME': 3,\n",
    "    'Consistent with SME but unsupported with data': 4,\n",
    "    'No expected relationship': 5,\n",
    "}\n",
    "# discrete_cmap = ListedColormap(['gainsboro', 'lightcoral', 'lightcoral', 'yellowgreen', 'yellowgreen', 'aliceblue'], name='flag_colors')\n",
    "discrete_cmap = ListedColormap(['gainsboro', red, red, green, green, 'aliceblue'], name='discrete_cmap') # color correspond to flag index\n",
    "\n",
    "for i, juri in enumerate(juris):\n",
    "    # process result for each juri\n",
    "    juri_result = result_df[result_df['juri'] == juri].drop(columns=['juri']).copy()\n",
    "    juri_result.loc[:, 'Treatment Time'] = juri_result['Treatment Time'].replace(year_map_dict)\n",
    "    juri_result.loc[:, 'Feature'] = juri_result['Feature'].apply(lambda x: x.replace('|idx=0', '').replace('_df0', ''))\n",
    "    juri_result : pd.DataFrame = juri_result.groupby(['Treatment Type', 'Feature']).apply(process_flag_group)\n",
    "    juri_result = juri_result.reset_index()\n",
    "    # generate pivoted map\n",
    "    flag_mat = juri_result.pivot(index='Feature', columns='Treatment Type', values='Flag')\n",
    "    time_mat = juri_result.pivot(index='Feature', columns='Treatment Type', values='Treatment Time')\n",
    "    effect_mat = juri_result.pivot(index='Feature', columns='Treatment Type', values='Known effect')\n",
    "    # process mat for annotation and color coding\n",
    "    annot_mat = np.where((flag_mat == 'Inconsistent with SME') | (flag_mat == 'Inconsistent with SME but explained with data'), time_mat.astype(str) + '\\n', '')\n",
    "    annot_mat[np.where(effect_mat < 0)] += '▼'\n",
    "    annot_mat[np.where(effect_mat > 0)] += '▲'\n",
    "    flag_mat = flag_mat.replace(flag_to_index)\n",
    "\n",
    "    sns.heatmap(\n",
    "        flag_mat,\n",
    "        cmap=discrete_cmap,\n",
    "        annot=annot_mat,\n",
    "        annot_kws={'color': 'black'},\n",
    "        linecolor='white', linewidth=1,\n",
    "        fmt='',\n",
    "        cbar=None,\n",
    "        ax=axs[i],\n",
    "    )\n",
    "    axs[i].set_title(juri)\n",
    "    \n",
    "    # add crosses to denote correlation is supported/ unsupported with data \n",
    "    cross_loc = np.where((flag_mat == 2) | (flag_mat == 4))\n",
    "    for start, end in zip(cross_loc[0], cross_loc[1]):\n",
    "        axs[i].add_patch(Rectangle((end, start), 1, 1, fill=False, hatch='x', edgecolor='black'))\n",
    "\n",
    "    if i == 1:\n",
    "        color_legend = axs[i].legend(\n",
    "            handles=[Patch(color=discrete_cmap(i)) for i in [0, 1, 3, 5]], \n",
    "            labels=['Weak correlation with feature', 'Inconsistent with SME', 'Consistent with SME', 'No expected relationship'],\n",
    "            loc='lower center',\n",
    "            bbox_to_anchor=(0.2, -0.2)\n",
    "        )\n",
    "        up_arrow = axs[i].scatter([], [], c='black', marker=u'$\\u25b2$', s=150, label='SME expects Positive correlation')\n",
    "        low_arrow = axs[i].scatter([], [], c='black', marker=u'$\\u25bc$', s=150, label='SME expects Negative correlation')\n",
    "        cross = Patch(facecolor='white', fill=False, hatch='xxxx', edgecolor='black', label='SME inconsistent with data')\n",
    "        up_arrow_model = axs[i].scatter([], [], c='red', marker=u'$\\u25b2$', s=150, label='Model expects Positive correlation')\n",
    "        low_arrow_model = axs[i].scatter([], [], c='red', marker=u'$\\u25bc$', s=150, label='Model expects Negative correlation')\n",
    "        axs[i].legend(handles=[up_arrow, low_arrow, up_arrow_model, low_arrow_model, cross], title='Icon Legend', bbox_to_anchor=(1, -0.1))\n",
    "        # axs[i].legend(title='Icon Legend', bbox_to_anchor=(1, -0.1))\n",
    "        axs[i].add_artist(color_legend)\n",
    "\n",
    "    # add red arrows \n",
    "    model_mat = juri_result.pivot(index='Feature', columns='Treatment Type', values='Model effect')\n",
    "    no_known_annot = np.zeros_like(effect_mat).astype(str)\n",
    "    no_known_annot[np.where((flag_mat == 5) & (model_mat > 0))] = '▲' \n",
    "    no_known_annot[np.where((flag_mat == 5) & (model_mat < 0))] = '▼' \n",
    "    no_known_annot[np.where((flag_mat != 5) | (model_mat == 0))] = '' \n",
    "    height, width = no_known_annot.shape\n",
    "    xpos = np.arange(width) + 0.5\n",
    "    ypos = np.arange(height) + 0.5\n",
    "    for i_xpos, x in enumerate(xpos):\n",
    "        for j_ypos, y in enumerate(ypos):\n",
    "            val = no_known_annot[j_ypos][i_xpos]\n",
    "            if val == '': continue\n",
    "            text_color = \"red\"\n",
    "            text_kwargs = dict(color=text_color, ha=\"center\", va=\"center\")\n",
    "            axs[i].text(x, y, val, **text_kwargs)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Color coded tables of feature effects. Effects considered only if correlation coefficient $> 0.5$\\nInconsistent effects (red) annotated with time horizons where inconsistency occurs.'\\\n",
    "   + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'summarised_over_time{\"_pos_background\" if use_pos_background else \"_all_background\"}_new.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot consistency between data and SME separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from src.visualization import plot_metric\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "df = result_df[\n",
    "    result_df['Correlation Flag'].str.startswith('Strong')\n",
    "].copy()\n",
    "known_vs_data = df.groupby('Consistency Flag')['Consistency Data Flag'].value_counts()\n",
    "known_vs_data.name = None\n",
    "\n",
    "known_vs_data = known_vs_data.reset_index().pivot(index='Consistency Flag', columns='Consistency Data Flag', values=0)\n",
    "known_vs_data.columns.name = None\n",
    "known_vs_data.index.name = None\n",
    "\n",
    "annot = known_vs_data.copy().astype(int)\n",
    "cmap = ListedColormap([red, green, aliceblue]) # color correspond to flag index\n",
    "# cmap = ListedColormap(['lightcoral', 'yellowgreen', 'aliceblue'])\n",
    "\n",
    "colors = known_vs_data.copy() \n",
    "colors.iloc[:, 0] = 1\n",
    "colors.iloc[:, 1] = 0\n",
    "colors.iloc[:, 2] = 2\n",
    "\n",
    "ax = sns.heatmap(colors, annot=annot, cmap=cmap, linecolor='white', linewidth=3, annot_kws={'fontsize': 20}, cbar=False, fmt='0d')\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "ax.tick_params(axis='y', rotation=0)\n",
    "# ax.set_xlabel('Model is')\n",
    "# ax.set_ylabel('Model is')\n",
    "ax.set_title(\n",
    "    \"Summary of agreement between subject-matter experts (SME) and models\"\\\n",
    "  + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance')\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / 'stat_summarised_comparison_effects_new.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of features against labels, annotated with known relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot distribution (no outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.shap_beeswarm import shap_summary\n",
    "\n",
    "input_dict = {\n",
    "    'WA': {'data': train_flattened_mrwa, 'labels': train_flattened_mrwa_labels},\n",
    "    'NZ': {'data': train_flattened_nzta, 'labels': train_flattened_nzta_labels},\n",
    "    'NSW': {'data': train_flattened_nsw, 'labels': train_flattened_nsw_labels},\n",
    "}\n",
    "\n",
    "wrong : pd.DataFrame = result_df[result_df['Correlation Flag'].str.startswith('Strong') & result_df['Consistency Flag'].str.startswith('Inconsistent')]\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "for i, (_, row) in enumerate(wrong.iterrows()):\n",
    "    eval_features = input_dict[row['juri']]['data']\n",
    "    eval_labels = input_dict[row['juri']]['labels']\n",
    "    col = (row['Treatment Time'], row['Treatment Type'])\n",
    "\n",
    "    with_labels = eval_labels[col] == 1\n",
    "    plot_df = pd.DataFrame(eval_features.loc[:, row['Feature']].copy())\n",
    "    plot_df['Has treatment'] = list(map({True: 'Yes', False: 'No'}.__getitem__, with_labels))\n",
    "\n",
    "    cmap = {'Yes': green, 'No': red}\n",
    "    \n",
    "    ax = plt.subplot(6, 6, i + 1)\n",
    "    # ax = plt.subplot(4, 4, i + 1)\n",
    "    # ax = plt.subplot(1, 1, 1)\n",
    "    if plot_df[row['Feature']].nunique() > 2:\n",
    "        sns.boxplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], showfliers=False, palette=cmap)\n",
    "    else:\n",
    "        plot_df = plot_df.groupby(['Has treatment'])[row['Feature']].mean().reset_index()\n",
    "        sns.barplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], palette=cmap)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    feature_name = row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\")\n",
    "    if feature_name.startswith(\"Pavement Type\") or feature_name.startswith(\"Surface Material\"):\n",
    "        expect_str = f'SME expects {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'\\n{row[\"Treatment Type\"]} treatment odds. '\\\n",
    "                    + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                    + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "    else:\n",
    "        expect_str = f'SME expects higher {feature_name.split(\"_\")[0]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'\\n{row[\"Treatment Type\"]} treatment odds. '\\\n",
    "                    + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                    + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "    ax.set_title(\n",
    "        f'{row[\"juri\"]} | {year_map_dict[row[\"Treatment Time\"]]}' +\\\n",
    "        f'\\n{expect_str}'\n",
    "    )\n",
    "\n",
    "    if row[\"Known effect\"] == row[\"Data effect\"]:\n",
    "        ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=red, alpha=0.2, zorder=-1)\n",
    "    else:\n",
    "        ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=green, alpha=0.2, zorder=-1)\n",
    "\n",
    "    axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "    ax.set_yticks((axis_to_data.transform((0, 0.1))[1], axis_to_data.transform((0, 0.9))[1]))\n",
    "    ax.set_yticklabels(['low', 'high'])\n",
    "\n",
    "    if eval_features[row['Feature']].nunique() > 2:\n",
    "        ax.set_ylabel(row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\"))\n",
    "    else:\n",
    "        ax.set_ylabel(f'Fraction with {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}')\n",
    "        plt.setp(ax.patches, linewidth=1, edgecolor='black')\n",
    "    ax.set_xlabel(f'Treatment: {row[\"Treatment Type\"]}')\n",
    "    ax.tick_params(axis='y', rotation=90)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Distribution of features against treatments for effects inconsistent with SME\"\\\n",
    "   + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance'),\n",
    "   fontsize=18\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98], w_pad=5.5)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / 'explain_inconsistent_boxplot_new.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot for individual juri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.shap_beeswarm import shap_summary\n",
    "\n",
    "input_dict = {\n",
    "    'WA': {'data': train_flattened_mrwa, 'labels': train_flattened_mrwa_labels},\n",
    "    'NZ': {'data': train_flattened_nzta, 'labels': train_flattened_nzta_labels},\n",
    "    'NSW': {'data': train_flattened_nsw, 'labels': train_flattened_nsw_labels},\n",
    "}\n",
    "\n",
    "wrong : pd.DataFrame = result_df[result_df['Correlation Flag'].str.startswith('Strong') & result_df['Consistency Flag'].str.startswith('Inconsistent')]\n",
    "\n",
    "for juri in wrong['juri'].unique():\n",
    "    df = wrong[wrong['juri'] == juri]\n",
    "    num_col = min([i for i in range(2, 10) if abs(i - (len(df) // i)) < 2])\n",
    "    num_row = int(np.ceil(len(df) / num_col))\n",
    "    fig = plt.figure(figsize=(num_col * 5, num_row * 5))\n",
    "\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        eval_features = input_dict[row['juri']]['data']\n",
    "        eval_labels = input_dict[row['juri']]['labels']\n",
    "        col = (row['Treatment Time'], row['Treatment Type'])\n",
    "\n",
    "        with_labels = eval_labels[col] == 1\n",
    "        plot_df = pd.DataFrame(eval_features.loc[:, row['Feature']].copy())\n",
    "        plot_df['Has treatment'] = list(map({True: 'Yes', False: 'No'}.__getitem__, with_labels))\n",
    "\n",
    "        cmap = {'Yes': green, 'No': red}\n",
    "        ax = plt.subplot(num_row, num_col, i + 1)\n",
    "\n",
    "        if plot_df[row['Feature']].nunique() > 2:\n",
    "            sns.boxplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], showfliers=False, palette=cmap)\n",
    "        else:\n",
    "            plot_df = plot_df.groupby(['Has treatment'])[row['Feature']].mean().reset_index()\n",
    "            sns.barplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], palette=cmap)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        feature_name = row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\")\n",
    "        if feature_name.startswith(\"Pavement Type\") or feature_name.startswith(\"Surface Material\"):\n",
    "            expect_str = f'SME expects {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'\\n{row[\"Treatment Type\"]} treatment odds. '\\\n",
    "                        + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                        + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "        else:\n",
    "            expect_str = f'SME expects higher {feature_name.split(\"_\")[0]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'\\n{row[\"Treatment Type\"]} treatment odds. '\\\n",
    "                        + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                        + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "\n",
    "        ax.set_title(\n",
    "            f'{row[\"juri\"]} | {year_map_dict[row[\"Treatment Time\"]]}' +\\\n",
    "            f'\\n{expect_str}'\n",
    "        )\n",
    "\n",
    "        if row[\"Known effect\"] == row[\"Data effect\"]:\n",
    "            ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=red, alpha=0.2, zorder=-1)\n",
    "        else:\n",
    "            ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=green, alpha=0.2, zorder=-1)\n",
    "\n",
    "        axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "        ax.set_yticks((axis_to_data.transform((0, 0.1))[1], axis_to_data.transform((0, 0.9))[1]))\n",
    "        ax.set_yticklabels(['low', 'high'])\n",
    "\n",
    "        if eval_features[row['Feature']].nunique() > 2:\n",
    "            ax.set_ylabel(row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\"))\n",
    "        else:\n",
    "            ax.set_ylabel(f'Fraction with {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}')\n",
    "            plt.setp(ax.patches, linewidth=1, edgecolor='black')\n",
    "        ax.set_xlabel(f'Treatment: {row[\"Treatment Type\"]}')\n",
    "        ax.tick_params(axis='y', rotation=90)\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Distribution of features against treatments for effects inconsistent with SME - Jurisdiction: {}\".format(juri)\\\n",
    "      + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance')\n",
    "    )\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98], w_pad=5.5)\n",
    "\n",
    "    inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "    if not inner_dir.exists():\n",
    "        inner_dir.mkdir()\n",
    "    plt.savefig(inner_dir / f'{juri}_explain_boxplot_new.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    'WA': {'data': train_flattened_mrwa, 'labels': train_flattened_mrwa_labels},\n",
    "    'NZ': {'data': train_flattened_nzta, 'labels': train_flattened_nzta_labels},\n",
    "    'NSW': {'data': train_flattened_nsw, 'labels': train_flattened_nsw_labels},\n",
    "}\n",
    "\n",
    "wrong : pd.DataFrame = result_df[result_df['Correlation Flag'].str.startswith('Strong') & result_df['Consistency Flag'].str.startswith('Inconsistent')]\n",
    "\n",
    "juri = 'NZ'\n",
    "year_type = 'Treatment between 1 to 3 years'\n",
    "feature = 'HeavyIndex_df0|idx=0'\n",
    "treatment_type = 'Resurfacing_SS'\n",
    "\n",
    "row = wrong[(wrong['juri'] == juri) & (wrong['Treatment Time'] == year_type) & (wrong['Treatment Type'] == treatment_type) & (wrong['Feature'] == feature)].iloc[0]\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "eval_features = input_dict[row['juri']]['data']\n",
    "eval_labels = input_dict[row['juri']]['labels']\n",
    "col = (row['Treatment Time'], row['Treatment Type'])\n",
    "\n",
    "with_labels = eval_labels[col] == 1\n",
    "plot_df = pd.DataFrame(eval_features.loc[:, row['Feature']].copy())\n",
    "plot_df['Has treatment'] = list(map({True: 'Yes', False: 'No'}.__getitem__, with_labels))\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "cmap = {'Yes': green, 'No': red}\n",
    "\n",
    "if plot_df[row['Feature']].nunique() > 2:\n",
    "    sns.boxplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], showfliers=False, palette=cmap)\n",
    "else:\n",
    "    plot_df = plot_df.groupby(['Has treatment'])[row['Feature']].mean().reset_index()\n",
    "    sns.barplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], palette=cmap)\n",
    "\n",
    "ax = plt.gca()\n",
    "feature_name = row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\")\n",
    "if feature_name.startswith(\"Pavement Type\") or feature_name.startswith(\"Surface Material\"):\n",
    "    expect_str = f'SME expects {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}\\nto ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'{row[\"Treatment Type\"]} treatment odds.'\\\n",
    "                + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "else:\n",
    "    expect_str = f'SME expects higher {feature_name.split(\"_\")[0]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + f'\\n{row[\"Treatment Type\"]} treatment odds. '\\\n",
    "                + '\\nModel predictions inconsistent.\\nData '\\\n",
    "                + ('supports subject-matter experts' if row[\"Data effect\"] == row['Known effect'] else ('supports models' if row['Data effect'] == row['Model effect'] else ' has no expectation'))\n",
    "ax.set_title(\n",
    "    f'{row[\"juri\"]} | {year_map_dict[row[\"Treatment Time\"]]}' +\\\n",
    "    f'\\n{expect_str}'\n",
    ")\n",
    "\n",
    "if row[\"Known effect\"] == row[\"Data effect\"]:\n",
    "    ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=red, alpha=0.2, zorder=-1)\n",
    "else:\n",
    "    ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color=green, alpha=0.2, zorder=-1)\n",
    "\n",
    "axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "ax.set_yticks((axis_to_data.transform((0, 0.1))[1], axis_to_data.transform((0, 0.9))[1]))\n",
    "ax.set_yticklabels(['low', 'high'])\n",
    "\n",
    "if eval_features[row['Feature']].nunique() > 2:\n",
    "    ax.set_ylabel(row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\"))\n",
    "else:\n",
    "    ax.set_ylabel(f'Fraction with {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}')\n",
    "    plt.setp(ax.patches, linewidth=1, edgecolor='black')\n",
    "ax.set_xlabel(f'Treatment: {row[\"Treatment Type\"]}')\n",
    "ax.tick_params(axis='y', rotation=90)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1], w_pad=5.5)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'boxplot_explain_sample.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.shap_beeswarm import shap_summary\n",
    "\n",
    "input_dict = {\n",
    "    'WA': {'data': train_flattened_mrwa, 'labels': train_flattened_mrwa_labels},\n",
    "    'NZ': {'data': train_flattened_nzta, 'labels': train_flattened_nzta_labels},\n",
    "    'NSW': {'data': train_flattened_nsw, 'labels': train_flattened_nsw_labels},\n",
    "}\n",
    "\n",
    "wrong_and_inconsistent_data = result_df[\n",
    "    (result_df['Consistency Flag'].str.startswith('Inconsistent with SME')) &\\\n",
    "    (result_df['Correlation Flag'].str.startswith('Strong')) &\\\n",
    "    (result_df['Consistency Data Flag'].str.startswith('Inconsistent'))\n",
    "]\n",
    "num_row = 5\n",
    "num_col = 2\n",
    "fig = plt.figure(figsize=(num_col * 5, num_row * 5))\n",
    "\n",
    "for i, (_, row) in enumerate(wrong_and_inconsistent_data.iterrows()):\n",
    "    eval_features = input_dict[row['juri']]['data']\n",
    "    eval_labels = input_dict[row['juri']]['labels']\n",
    "    col = (row['Treatment Time'], row['Treatment Type'])\n",
    "\n",
    "    with_labels = eval_labels[col] == 1\n",
    "    plot_df = pd.DataFrame(eval_features.loc[:, row['Feature']].copy())\n",
    "    plot_df['Has treatment'] = list(map({True: 'Yes', False: 'No'}.__getitem__, with_labels))\n",
    "\n",
    "    cmap = {'Yes': green, 'No': red}\n",
    "    ax = plt.subplot(num_row, num_col, i+1)\n",
    "\n",
    "    if plot_df[row['Feature']].nunique() > 2:\n",
    "        sns.boxplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], showfliers=False, palette=cmap)\n",
    "    else:\n",
    "        plot_df = plot_df.groupby(['Has treatment'])[row['Feature']].mean().reset_index()\n",
    "        sns.barplot(data=plot_df, x='Has treatment', y=row['Feature'], order=['Yes', 'No'], palette=cmap)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    feature_name = row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\")\n",
    "    if feature_name.startswith(\"Pavement Type\") or feature_name.startswith(\"Surface Material\"):\n",
    "        expect_str = f'Expect {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}\\nto ' + ('increase' if row['Known effect'] > 0 else 'decrease') + ' treatment odds.\\nObserve ' + ('opposite' if row[\"Data effect\"] != row['Known effect'] else 'the same')\n",
    "    else:\n",
    "        expect_str = f'Expect higher {feature_name.split(\"_\")[0]} to ' + ('increase' if row['Known effect'] > 0 else 'decrease') + ' treatment odds.\\nObserve ' + ('opposite' if row[\"Data effect\"] != row['Known effect'] else 'the same')\n",
    "    ax.set_title(\n",
    "        f'{row[\"juri\"]} | {year_map_dict[row[\"Treatment Time\"]]} - {row[\"Treatment Type\"]}' +\\\n",
    "        f'\\n{expect_str}'\n",
    "    )\n",
    "\n",
    "    axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "    ax.set_yticks((axis_to_data.transform((0, 0.1))[1], axis_to_data.transform((0, 0.9))[1]))\n",
    "    ax.set_yticklabels(['low', 'high'])\n",
    "\n",
    "    if row[\"Known effect\"] == row[\"Data effect\"]:\n",
    "        ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color='lightcoral', alpha=0.2, zorder=-1)\n",
    "    else:\n",
    "        ax.fill_between(x=ax.get_xlim(), y1=ax.get_ylim()[0], y2=ax.get_ylim()[1], color='yellowgreen', alpha=0.2, zorder=-1)\n",
    "\n",
    "    if eval_features[row['Feature']].nunique() > 2:\n",
    "        ax.set_ylabel(row[\"Feature\"].replace(\"_df0\", \"\").replace(\"|idx=0\", \"\"))\n",
    "    else:\n",
    "        ax.set_ylabel(f'Fraction with {feature_name.split(\"_\")[0]} being {feature_name.split(\"_\")[1]}')\n",
    "        plt.setp(ax.patches, linewidth=1, edgecolor='black')\n",
    "    ax.set_xlabel('Has treatment')\n",
    "    ax.tick_params(axis='y', rotation=90)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Distribution of features against treatments for effects inconsistent with SME and inconsistent with data\"\\\n",
    "    + ('' if SUFFIX != 'balanced_sampled' else f'\\nSampling performed to correct for class imbalance')\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98], w_pad=5.5)\n",
    "\n",
    "inner_dir = save_fig_dir / 'heatmap_feature_effects'\n",
    "if not inner_dir.exists():\n",
    "    inner_dir.mkdir()\n",
    "plt.savefig(inner_dir / f'unexplain_inconsistent.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "juris = ['NSW', 'VIC', 'NZ', 'WA']\n",
    "datasets = [train_flattened_nsw, train_flattened_vic, train_flattened_nzta, train_flattened_mrwa] \n",
    "colors = ['orange', 'green', 'red', 'blue']\n",
    "cutoff = (0.05, 0.95)\n",
    "\n",
    "if (save_fig_dir / 'raw_results_pdp_all.pkl').exists():\n",
    "    with open(save_fig_dir / 'raw_results_pdp_all.pkl', 'rb') as f:\n",
    "        raw_pdp_result = pickle.load(f)\n",
    "else:\n",
    "    raw_pdp_result = {juri: {} for juri in juris} \n",
    "\n",
    "for juri, c, eval_features in zip(juris, colors, datasets):\n",
    "\n",
    "    for feature_idx, feature in enumerate(eval_features.columns): \n",
    "        if feature_idx <= 9:\n",
    "            continue\n",
    "        if feature not in raw_pdp_result[juri]:\n",
    "            raw_pdp_result[juri][feature] = {}\n",
    "\n",
    "        fig = plt.figure(figsize=(24, 60))\n",
    "        gs = gridspec.GridSpec(5, 4, figure=fig) # 5 rows for 5 times, 4 cols for 4 treatments\n",
    "\n",
    "        # calculate quantile cut off\n",
    "        if eval_features[feature].nunique() > 2:\n",
    "            low, high = np.quantile(eval_features[feature], cutoff)\n",
    "        else:\n",
    "            low, high = sorted(eval_features[feature].unique()) \n",
    "        if low == high:\n",
    "            low, high = eval_features[feature].min(), eval_features[feature].max()\n",
    " \n",
    "        row_dict = {t: i for i, t in enumerate(['within 1 year', 'between 1 to 3 years', 'between 3 to 5 years', 'between 5 to 10 years', 'between 10 to 30 years'])}\n",
    "        col_dict = {t: i for i, t in enumerate(['Resurfacing_SS', 'Resurfacing_AC', 'Major Patching', 'Rehabilitation'])}\n",
    "\n",
    "        for col_idx, col in enumerate(model_dict[juri]['prediction_columns']):\n",
    "            if col[1] not in col_dict:\n",
    "                continue\n",
    "            # for testing:\n",
    "            if col != ('Treatment within 1 year', 'Resurfacing_SS'):\n",
    "                continue\n",
    "\n",
    "            nested_gs = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=gs[row_dict[col[0].replace('Treatment ', '')], col_dict[col[1]]], hspace=0.1)\n",
    "            ax = fig.add_subplot(nested_gs[:2, :])\n",
    "            frequency_ax = fig.add_subplot(nested_gs[2, :], sharex=ax)\n",
    "            col_name = f\"{col[0].replace('Treatment ', '')} - {col[1].replace('Resurfacing_', '')}\" \n",
    "            ax.set_title(col_name)\n",
    "\n",
    "            estimator_idx = np.argwhere(model_dict[juri]['prediction_columns'] == col).flatten()\n",
    "            if estimator_idx.size != 1:\n",
    "                continue\n",
    "            all_means, true_means, prev_values = [], [], None\n",
    "            if estimator_idx[0] not in raw_pdp_result[juri][feature]:\n",
    "                raw_pdp_result[juri][feature][estimator_idx[0]] = {}\n",
    "            for model_idx, model in enumerate(model_dict[juri]['models']['XGB']):\n",
    "                if (model_idx not in raw_pdp_result[juri][feature][estimator_idx[0]]) or (raw_pdp_result[juri][feature][estimator_idx[0]][model_idx] is None):\n",
    "                    results = partial_dependence(\n",
    "                        model.estimators_[estimator_idx[0]],\n",
    "                        X=eval_features,\n",
    "                        features=[feature],\n",
    "                        kind='average'\n",
    "                    )\n",
    "                    raw_pdp_result[juri][feature][estimator_idx[0]][model_idx] = results\n",
    "                    with open(save_fig_dir / 'raw_results_pdp_all.pkl', 'wb') as f:\n",
    "                        pickle.dump(raw_pdp_result, f)\n",
    "                else:\n",
    "                    results = raw_pdp_result[juri][feature][estimator_idx[0]][model_idx]\n",
    "\n",
    "                # filter by percentile\n",
    "                plot_x, plot_y = results['values'][0], results['average'][0]\n",
    "                plot_idx = np.where((plot_x >= low) & (plot_x <= high))\n",
    "\n",
    "                ax.plot(plot_x[plot_idx], plot_y[plot_idx], label=juri, color=c, alpha=0.2)\n",
    "                all_means.append(plot_y[plot_idx])\n",
    "                prev_values = plot_x[plot_idx] if prev_values is None else (None if (prev_values != plot_x[plot_idx]).any() else prev_values)\n",
    "                assert prev_values is not None\n",
    "\n",
    "                # get true predictions\n",
    "                true_means.append(np.mean(model.estimators_[estimator_idx[0]].predict(np.array(eval_features)), axis=0))\n",
    "\n",
    "            ax.plot(prev_values, np.array(all_means).mean(axis=0), label=juri, color=c, alpha=1)\n",
    "            ax.axhline(np.array(true_means).mean(axis=0), xmin=prev_values.min(), xmax=prev_values.max(), label='Actual %', color='red', alpha=1)\n",
    "            ax.tick_params(axis='y', labelcolor=c)\n",
    "\n",
    "            # plot frequency\n",
    "            if eval_features[feature].nunique() > 2:\n",
    "                sns.kdeplot(data=eval_features, x=feature, clip=(low, high), shade=True, ax=frequency_ax, color=c)\n",
    "            else:\n",
    "                count_0 = (eval_features[feature] == low).sum()\n",
    "                count_1 = (eval_features[feature] == high).sum()\n",
    "                sns.barplot(x=[low, high], y=[count_0, count_1], ax=frequency_ax, color=c)\n",
    "            frequency_ax.invert_yaxis()\n",
    "\n",
    "        fig.supylabel('% of positive labels')\n",
    "        fig.suptitle(\n",
    "            f'Partial Dependency Plot - {juri}\\n{feature.replace(\"_df0|idx=0\", \"\")}',\n",
    "            fontsize=25\n",
    "        )\n",
    "        fig.tight_layout(rect=[0.03, 0.03, 1, 0.95])\n",
    "        inner_dir = save_fig_dir / 'constrained_pdp'\n",
    "        if not inner_dir.exists(): inner_dir.mkdir()\n",
    "        plt.savefig(inner_dir / f'pdp_{juri}_{feature.replace(\"_df0|idx=0\", \"\")}.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('austroads_taskA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8558eca60468214515578ef8dc9d1a3cd923df7ae0c7c3b68d36aadcc2987ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
